{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVOn8CESyQsT",
        "outputId": "55b58bc4-867b-4c6e-aa9d-eab1f604464f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['data', 'scripts', 'seeds.txt', 'rag.py', 'system_outputs', 'index', '__pycache__', 'run_rag_colab.ipynb']\n",
            "== sparse ==\n",
            "N=240  EM=0.087  F1=0.192  non-empty=1.000  non-'unknown'=0.867\n",
            "Per-bucket:\n",
            "  cmu-facts     n= 39  EM=0.154  F1=0.283\n",
            "  events        n= 19  EM=0.053  F1=0.118\n",
            "  other         n= 22  EM=0.091  F1=0.158\n",
            "  pgh-facts     n= 68  EM=0.029  F1=0.098\n",
            "  when/date     n= 31  EM=0.065  F1=0.231\n",
            "  where/venue   n= 57  EM=0.105  F1=0.220\n",
            "  who/person    n=  4  EM=0.500  F1=0.714\n",
            "\n",
            "== dense ==\n",
            "N=240  EM=0.121  F1=0.222  non-empty=1.000  non-'unknown'=0.871\n",
            "Per-bucket:\n",
            "  cmu-facts     n= 39  EM=0.128  F1=0.228\n",
            "  events        n= 19  EM=0.105  F1=0.294\n",
            "  other         n= 22  EM=0.091  F1=0.176\n",
            "  pgh-facts     n= 68  EM=0.088  F1=0.137\n",
            "  when/date     n= 31  EM=0.097  F1=0.228\n",
            "  where/venue   n= 57  EM=0.140  F1=0.274\n",
            "  who/person    n=  4  EM=0.750  F1=0.750\n",
            "\n",
            "== hybrid ==\n",
            "N=240  EM=0.129  F1=0.242  non-empty=1.000  non-'unknown'=1.000\n",
            "Per-bucket:\n",
            "  cmu-facts     n= 39  EM=0.179  F1=0.314\n",
            "  events        n= 19  EM=0.053  F1=0.106\n",
            "  other         n= 22  EM=0.091  F1=0.266\n",
            "  pgh-facts     n= 68  EM=0.088  F1=0.135\n",
            "  when/date     n= 31  EM=0.161  F1=0.298\n",
            "  where/venue   n= 57  EM=0.140  F1=0.299\n",
            "  who/person    n=  4  EM=0.500  F1=0.600\n",
            "\n",
            "Ablation (EM/F1):\n",
            "  sparse  EM=0.087   F1=0.192\n",
            "  dense   EM=0.121   F1=0.222\n",
            "  hybrid  EM=0.129   F1=0.242\n",
            "\n",
            "Hybrid vs Sparse:\n",
            "  paired t-test on F1: t=2.607, p≈0.0091\n",
            "  McNemar on EM: b01=3, b10=13, chi2=5.062, p≈0.0244\n",
            "\n",
            "Hybrid vs Dense:\n",
            "  paired t-test on F1: t=0.890, p≈0.3735\n",
            "  McNemar on EM: b01=9, b10=11, chi2=0.050, p≈0.8231\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "print(os.listdir('/content/drive/MyDrive/rag-pgh'))\n",
        "from pathlib import Path\n",
        "import json, re, string, collections, math\n",
        "\n",
        "# --- Paths ---\n",
        "root = Path(\"/content/drive/MyDrive/rag-pgh\")\n",
        "q_path   = root/\"data/test/questions.txt\"\n",
        "ref_path = root/\"data/test/reference_answers.json\"\n",
        "\n",
        "paths = {\n",
        "    \"sparse\": root/\"data/test/system_output_sparse.json\",\n",
        "    \"dense\":  root/\"data/test/system_output_dense.json\",\n",
        "    \"hybrid\": root/\"data/test/system_output_test.json\",\n",
        "}\n",
        "\n",
        "# --- Normalization ---\n",
        "def _normalize_text(s: str) -> str:\n",
        "    s = s.lower().strip()\n",
        "    s = s.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    return \" \".join(s.split())\n",
        "\n",
        "def _f1_single(pred: str, gold: str) -> float:\n",
        "    ptoks = _normalize_text(pred).split()\n",
        "    gtoks = _normalize_text(gold).split()\n",
        "    if not ptoks and not gtoks: return 1.0\n",
        "    if not ptoks or not gtoks:  return 0.0\n",
        "    common = collections.Counter(ptoks) & collections.Counter(gtoks)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0: return 0.0\n",
        "    precision = num_same / len(ptoks)\n",
        "    recall    = num_same / len(gtoks)\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "def _best_em_f1(pred: str, gold_variants: str):\n",
        "    \"\"\"gold_variants may contain multiple references separated by ';'.\"\"\"\n",
        "    vars_ = [g.strip() for g in gold_variants.split(\";\") if g.strip()]\n",
        "    if not vars_: return 0, 0.0\n",
        "    pnorm = _normalize_text(pred)\n",
        "    best_em, best_f1 = 0, 0.0\n",
        "    for g in vars_:\n",
        "        gnorm = _normalize_text(g)\n",
        "        em = int(pnorm == gnorm)\n",
        "        f1 = _f1_single(pred, g)\n",
        "        best_em = max(best_em, em)\n",
        "        best_f1 = max(best_f1, f1)\n",
        "    return best_em, best_f1\n",
        "\n",
        "# --- Buckets for analysis  ---\n",
        "_MONTH = r\"(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\"\n",
        "_DATE  = rf\"(\\b{_MONTH}\\b|\\b{_MONTH}[a-z]*\\b|\\b\\d{{1,2}}/\\d{{1,2}}\\b|\\b\\d{{4}}\\b)\"\n",
        "\n",
        "_BUCKETS = {\n",
        "    \"when/date\":   re.compile(rf\"\\b(when|date|year|on)\\b|{_DATE}\", re.I),\n",
        "\n",
        "    \"who/person\":  re.compile(r\"\\b(who|artist|singer|performer|mayor)\\b\", re.I),\n",
        "\n",
        "    #\n",
        "    \"where/venue\": re.compile(r\"\\b(where|located|venue)\\b|\\b(Hall|Center|Park|Museum|Arena|Theater|Theatre|Stadium)\\b\", re.I),\n",
        "\n",
        "    # events\n",
        "    \"events\":      re.compile(r\"\\b(event|concert|festival|show)\\b|\\bPPG\\b\", re.I),\n",
        "\n",
        "    \"cmu-facts\":   re.compile(r\"\\b(cmu|carnegie mellon)\\b\", re.I),\n",
        "    \"pgh-facts\":   re.compile(r\"\\b(pittsburgh)\\b\", re.I),\n",
        "}\n",
        "\n",
        "_BUCKET_ORDER = [\"when/date\", \"who/person\", \"where/venue\", \"events\", \"cmu-facts\", \"pgh-facts\"]\n",
        "\n",
        "def bucket_question(q: str) -> str:\n",
        "    for name in _BUCKET_ORDER:\n",
        "        if _BUCKETS[name].search(q):\n",
        "            return name\n",
        "    return \"other\"\n",
        "\n",
        "# --- evaluation for a single system output ---\n",
        "def evaluate_one(sys_path: Path):\n",
        "    questions = [l.strip() for l in q_path.read_text(encoding=\"utf-8\").splitlines() if l.strip()]\n",
        "    gold = json.loads(ref_path.read_text(encoding=\"utf-8\"))\n",
        "    pred = json.loads(sys_path.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "    exp = [str(i+1) for i in range(len(questions))]\n",
        "    assert list(gold.keys()) == exp, \"reference_answers.json keys must be '1'..'N'\"\n",
        "    assert list(pred.keys()) == exp, \"system_output.json keys must be '1'..'N'\"\n",
        "\n",
        "    perq = []\n",
        "    ems, f1s = [], []\n",
        "    nonempty = nonunknown = 0\n",
        "\n",
        "    for i, q in enumerate(questions, start=1):\n",
        "        k = str(i)\n",
        "        p = pred.get(k, \"\")\n",
        "        g = gold.get(k, \"\")\n",
        "        em, f1 = _best_em_f1(p, g)\n",
        "        ems.append(em); f1s.append(f1)\n",
        "        nonempty   += int(bool(p.strip()))\n",
        "        nonunknown += int(p.strip().lower() not in (\"unknown\", \"\"))\n",
        "\n",
        "        perq.append({\n",
        "            \"id\": i, \"bucket\": bucket(q), \"question\": q,\n",
        "            \"pred\": p, \"gold\": g, \"EM\": em, \"F1\": f1\n",
        "        })\n",
        "\n",
        "    # macro\n",
        "    EM = sum(ems)/len(ems)\n",
        "    F1 = sum(f1s)/len(f1s)\n",
        "\n",
        "    # per bucket\n",
        "    by_b = collections.defaultdict(lambda: {\"n\":0,\"EM\":0.0,\"F1\":0.0})\n",
        "    for r in perq:\n",
        "        b = r[\"bucket\"]; by_b[b][\"n\"] += 1; by_b[b][\"EM\"] += r[\"EM\"]; by_b[b][\"F1\"] += r[\"F1\"]\n",
        "    buckets = {b: {\"n\":v[\"n\"], \"EM\": v[\"EM\"]/v[\"n\"] if v[\"n\"] else 0.0,\n",
        "                        \"F1\": v[\"F1\"]/v[\"n\"] if v[\"n\"] else 0.0}\n",
        "               for b,v in by_b.items()}\n",
        "\n",
        "    return {\n",
        "        \"N\": len(questions),\n",
        "        \"EM\": EM, \"F1\": F1,\n",
        "        \"nonempty_rate\": nonempty/len(questions),\n",
        "        \"nonunknown_rate\": nonunknown/len(questions),\n",
        "        \"per_question\": perq,\n",
        "        \"per_bucket\": buckets\n",
        "    }\n",
        "\n",
        "def print_summary(name: str, r: dict):\n",
        "    print(f\"== {name} ==\")\n",
        "    print(f\"N={r['N']}  EM={r['EM']:.3f}  F1={r['F1']:.3f}  non-empty={r['nonempty_rate']:.3f}  non-'unknown'={r['nonunknown_rate']:.3f}\")\n",
        "    if r[\"per_bucket\"]:\n",
        "        print(\"Per-bucket:\")\n",
        "        for b, v in sorted(r[\"per_bucket\"].items()):\n",
        "            print(f\"  {b:12s}  n={v['n']:>3}  EM={v['EM']:.3f}  F1={v['F1']:.3f}\")\n",
        "    print()\n",
        "\n",
        "results = {}\n",
        "for name, p in paths.items():\n",
        "    if p.exists():\n",
        "        results[name] = evaluate_one(p)\n",
        "        print_summary(name, results[name])\n",
        "    else:\n",
        "        print(f\"[warn] Missing file for {name}: {p}\")\n",
        "\n",
        "# --- Simple ablation table ---\n",
        "print(\"Ablation (EM/F1):\")\n",
        "for name in [\"sparse\", \"dense\", \"hybrid\"]:\n",
        "    if name in results:\n",
        "        print(f\"  {name:6s}  EM={results[name]['EM']:.3f}   F1={results[name]['F1']:.3f}\")\n",
        "\n",
        "# --- Significance tests: paired t-test on F1, McNemar on EM ---\n",
        "def paired_t_test_F1(resA, resB):\n",
        "    A = [r[\"F1\"] for r in resA[\"per_question\"]]\n",
        "    B = [r[\"F1\"] for r in resB[\"per_question\"]]\n",
        "    assert len(A)==len(B)\n",
        "    diffs = [a-b for a,b in zip(A,B)]\n",
        "    n = len(diffs)\n",
        "    mean_d = sum(diffs)/n\n",
        "    var_d  = sum((d-mean_d)**2 for d in diffs)/(n-1) if n>1 else 0.0\n",
        "    se     = (var_d/n)**0.5 if n>0 else 1.0\n",
        "    t = mean_d/se if se>0 else 0.0\n",
        "    # Normal approx to p-value (fine at N>=30)\n",
        "    from math import erf, sqrt\n",
        "    p = 2*(1 - 0.5*(1+erf(abs(t)/sqrt(2))))\n",
        "    return t, p\n",
        "\n",
        "def mcnemar_EM(resA, resB):\n",
        "    A = [r[\"EM\"] for r in resA[\"per_question\"]]\n",
        "    B = [r[\"EM\"] for r in resB[\"per_question\"]]\n",
        "    b01 = sum(1 for a,b in zip(A,B) if a==0 and b==1)  # B correct, A wrong\n",
        "    b10 = sum(1 for a,b in zip(A,B) if a==1 and b==0)  # A correct, B wrong\n",
        "    # Continuity-corrected chi^2\n",
        "    chi2 = ((abs(b01-b10)-1)**2) / (b01+b10) if (b01+b10)>0 else 0.0\n",
        "    from math import erf, sqrt\n",
        "    p = 1 - erf((chi2/2)**0.5)\n",
        "    return b01, b10, chi2, p\n",
        "\n",
        "if \"hybrid\" in results and \"sparse\" in results:\n",
        "    t,p = paired_t_test_F1(results[\"hybrid\"], results[\"sparse\"])\n",
        "    b01,b10,chi2,pm = mcnemar_EM(results[\"hybrid\"], results[\"sparse\"])\n",
        "    print(\"\\nHybrid vs Sparse:\")\n",
        "    print(f\"  paired t-test on F1: t={t:.3f}, p≈{p:.4f}\")\n",
        "    print(f\"  McNemar on EM: b01={b01}, b10={b10}, chi2={chi2:.3f}, p≈{pm:.4f}\")\n",
        "\n",
        "if \"hybrid\" in results and \"dense\" in results:\n",
        "    t,p = paired_t_test_F1(results[\"hybrid\"], results[\"dense\"])\n",
        "    b01,b10,chi2,pm = mcnemar_EM(results[\"hybrid\"], results[\"dense\"])\n",
        "    print(\"\\nHybrid vs Dense:\")\n",
        "    print(f\"  paired t-test on F1: t={t:.3f}, p≈{p:.4f}\")\n",
        "    print(f\"  McNemar on EM: b01={b01}, b10={b10}, chi2={chi2:.3f}, p≈{pm:.4f}\")\n"
      ]
    }
  ]
}